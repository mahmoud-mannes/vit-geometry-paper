@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{
chu2023conditional,
title={Conditional Positional Encodings for Vision Transformers},
author={Xiangxiang Chu and Zhi Tian and Bo Zhang and Xinlong Wang and Chunhua Shen},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=3KWnuT-R1bh}
}

@inproceedings{
raghu2021do,
title={Do Vision Transformers See Like Convolutional Neural Networks?},
author={Maithra Raghu and Thomas Unterthiner and Simon Kornblith and Chiyuan Zhang and Alexey Dosovitskiy},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=R-616EWWKF5}
}

@inproceedings{
Islam*2020How,
title={How much Position Information Do Convolutional Neural Networks Encode?},
author={Md Amirul Islam* and Sen Jia* and Neil D. B. Bruce},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJeB36NKvB}
}
@article{amirhossein2023,
    title = {The Impact of Positional Encoding on Length Generalization in Transformers},
    author = {Kazemnejad and Padhi and others},
    year = {2023}
}