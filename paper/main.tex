\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage[preprint]{icml2026}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{placeins}


\begin{document}

\twocolumn[
    \icmltitle{What Positional Embeddings Really Do In Vision Transformers}

    \begin{icmlauthorlist}
    \icmlauthor{Mahmoud Mannes}{ind}
    \end{icmlauthorlist}

    \icmlaffiliation{ind}{Independent Researcher}

    \icmlkeywords{Vision Transformers, Positional Embeddings, Representational Geometry, Mechanistic Interpretability}

    \vskip 0.3in
]
\icmlcorrespondingauthor{Mahmoud Mannes}{mannesmahmoud@gmail.com}
\printAffiliationsAndNotice{}

\begin{abstract}
    Positional embeddings (PEs) in Vision Transformers (ViTs) are often viewed as simple spatial injectors that enable the encoding of absolute position. In this work, we show that even ViTs trained without PEs can recover non-trivial spatial structure and distinguish relative position using patch content alone. This raises a central question: if spatial structure can emerge without PEs, what functional role do PEs actually play? We find that PEs causally induce a dramatic increase in early-layer representational diversity, characterized by higher effective rank and reduced token homogenization in the residual stream. This effect arises prior to the encoder blocks and encourages representations that jointly leverage positional information and patch content. In contrast, models without PEs rely exclusively on content-based heuristics to infer spatial structure, resulting in representations that are significantly more fragile under distributional shifts.

\end{abstract}
\section{Introduction}
    Vision Transformers (ViTs) have emerged as a powerful alternative to convolutional architectures for visual recognition by modeling images as sequences of patch tokens processed through self-attention mechanisms \cite{originalvit2020}. Unlike Convolutional Neural Networks (CNNs), however, ViTs lack strong built-in inductive biases toward locality and translation equivariance. As a result, most ViT architectures rely on Positional Embeddings (PEs) to inject explicit spatial information, enabling the model to distinguish between patches originating from different locations in the image.

    Despite their widespread use, the precise role of positional embeddings in vision transformers remains incompletely understood. While PEs are generally assumed to be essential for encoding spatial structure, several empirical studies have shown that ViTs can retain non-trivial performance even when explicit positional information is removed or degraded \cite{chu2021}. These findings suggest that transformers may partially reconstruct spatial relationships from patch content alone, much like how CNNS learn implicit positional information from zero-padding \cite{islam2020}, raising questions about what functional advantages positional embeddings actually provide beyond basic spatial identifiability.

    Most prior work has investigated the role of positional embeddings primarily through downstream performance metrics or architectural variations. While informative, such analyses offer limited insight into how positional information influences the internal representations learned by the model. In particular, the impact of positional embeddings on the geometry, dimensionality, and stability of token representations throughout the transformer stack has received comparatively little attention.

    In this work, we adopt a mechanistic perspective to study the role of positional embeddings in Vision Transformers. We analyze the evolution of token representations in the residual stream using tools from representational geometry \cite{raghu2021}, with the goal of characterizing how spatial structure emerges and is maintained across layers. To support this analysis, we introduce the Spatial Structure–Diagonal Coefficient (SSDC), a metric designed to quantify the degree to which spatial relationships are reflected in token similarity patterns.

    Using this framework, we conduct a comparative study of ViT models trained with and without positional embeddings. We examine how positional embeddings affect representational dimensionality, the nature of spatial reasoning employed by the model, and robustness to distributional shifts such as stylization and noise. Together, our results provide a more detailed picture of how explicit positional signals shape the internal organization of vision transformers, offering new insight into why positional embeddings play a critical role in stable and robust visual representation learning.



\section{Background and Setup}

    \subsection{Vision Transformer Architecture}
        All models used in our experiments are vanilla Vision Transformers trained from scratch, with approximately 1.2M parameters. Images are divided into fixed-size patches, which are linearly projected into token embeddings and processed by a stack of self-attention and feedforward layers. When present, positional embeddings are learned parameters optimized jointly with the rest of the model. No architectural modifications or auxiliary inductive biases are introduced beyond standard ViT components.

    \subsection{Positional Embedding Ablation}
        To isolate the functional role of positional embeddings, we train a parallel set of models in which positional embeddings are entirely removed. Throughout the paper, we refer to models trained without positional embeddings as \emph{ablated models}, and to models trained with positional embeddings as \emph{intact models}. Apart from the presence or absence of positional embeddings, all architectural choices, optimization settings, and training procedures are held constant.

    \subsection{Datasets}
        We evaluate models on CIFAR-10 and a stylized variant derived from CIFAR-10 to assess robustness under distributional shift. The stylized dataset is generated using Adaptive Instance Normalization (AdaIN) with a mixing coefficient $\alpha = 0.1$, which significantly alters texture statistics while preserving coarse spatial structure. Models are trained on standard CIFAR-10 images and evaluated on both the original and stylized datasets.
\section{Methods}

    \subsection{Residual Stream Geometry}
    To analyze the evolution of internal representations across depth, we extract the residual stream at selected layers of the model (layers 0, 2, 4, and 9, where layer 9 corresponds to the final layer). At each layer, we represent the residual stream as a matrix
    $R \in \mathbb{R}^{T \times C}$, where $T$ denotes the number of tokens and $C$ the embedding dimension. Each row of $R$ corresponds to the residual stream representation of a single token.

    Given the singular values $\{\sigma_i\}$ of $R$, we compute the effective rank using the participation ratio:
    \[
    \mathrm{ER} = \frac{\left(\sum_i \sigma_i^2\right)^2}{\sum_i \sigma_i^4}.
    \]
    Effective rank quantifies the number of dimensions that meaningfully contribute to the representation, with higher values indicating more distributed and heterogeneous representations.

    In addition, we compute pairwise cosine similarities between all token representations in $R$ to form a token cosine similarity matrix, where the $(i,j)$-th entry corresponds to the cosine similarity between tokens $i$ and $j$. This matrix is symmetric by construction. We average the token cosine similarity matrix across the batch dimension to obtain a layer-wise summary of inter-token relationships. This matrix serves both as a proxy for inter-token heterogeneity and as the basis for computing the Spatial Similarity Distance Correlation (SSDC).

    \subsection{Spatial Similarity Distance Correlation}
    To quantify the emergence of spatial structure, we introduce the Spatial Similarity 
    Distance Correlation (SSDC). For a given layer, we compute the pairwise cosine similarity
    matrix between token representations and the corresponding matrix of pairwise spatial 
    distances between token positions, where Spatial distance is defined as the Manhattan distance 
    between patch coordinates on the image grid. SSDC is defined as the Spearman rank correlation 
    between cosine similarity and the negative spatial distance, such that higher values 
    indicate that tokens which are spatially closer tend to have more similar representations. 
    Because SSDC measures the monotonic alignment between spatial proximity and representational
    similarity, it serves as a proxy for the presence of relative positional structure in the 
    residual stream.

    We use Spearman rank correlation to remain agnostic to the precise functional form relating 
    spatial distance and representational similarity.

    \subsection{Fragility Score}
    To quantify a model’s sensitivity to distributional shifts, we define a simple
    \emph{Fragility Score} (FS), which measures the relative drop in top-1 accuracy
    under distribution shift. It is defined as
    \[
    \mathrm{FS} = 1 - \frac{A_{\text{shift}}}{A_{\text{normal}}},
    \]
    where $A_{\text{normal}}$ and $A_{\text{shift}}$ denote top-1 accuracy on the
    normal and shifted datasets, respectively. Higher values indicate greater
    performance degradation.
\section{Results}
    \subsection{Architectural Priors Induce Static Spatial Correlations at Initialization}
        \begin{minipage}{\linewidth}
            \textbf{Experimental Setup:} We evaluate SSDC at layers 0, 2, 4, and 9 on the CIFAR-10 dataset
            using untrained ablated models. 
            We also extract from each one of these layers the Token Cosine
            Similarity Matrix and plot them using the same color scale (Appendix Fig. A2).
        \end{minipage}
        
        
        \begin{figure}[t]
            \centering
            \includegraphics[width=0.8\linewidth]{../figures/SSDC_section_41}
            \caption{\textbf{SSDC across depth for an untrained ablated model.} SSDC remains approximately constant across layers, indicating static spatial correlations induced by architectural and data priors rather than learning. Shaded regions indicate variability across runs.}
            \label{fig:SSDC}
        \end{figure}

        \textbf{Results}:
        The untrained ablated model exhibits a non-zero SSDC (~0.5) that remains approximately constant across depth (Fig. 1). This behavior is consistent across runs and indicates the presence of static spatial correlations induced by architectural and data priors rather than learning. Importantly, SSDC magnitude alone is insufficient to characterize learned spatial organization; instead, changes in SSDC across depth are the relevant signal.
        
        This static spatial structure can be visually demonstrated by token cosine similarity heatmaps that are shown in Appendix Fig. A1. 

        This provides a static baseline against which we can measure the emergence of learned spatial structure in trained models.

    \subsection{Validating Emergent Spatial Structure via Extreme Counterfactuals}
        \begin{minipage}{\linewidth}
            \textbf{Experimental setup:} We compute Token Cosine Similarity Matrices from layers 0, 2, 4, and 9 and evaluate the proposed SSDC metric. We compare three settings: (i) an untrained model with tokens randomly permuted at inference time, serving as an extreme baseline with no spatial structure; (ii) a trained model without positional embeddings (trained ablated); and (iii) a fully trained intact model.
        \end{minipage}


        \textbf{Results:} The untrained model with random permutation exhibits a consistently negative and depth-invariant SSDC value, reflecting the absence of meaningful spatial organization in token representations. In contrast, the trained ablated model shows a clear and consistent increase in SSDC from layer 0 to layer 2, after which SSDC remains roughly constant across deeper layers (Fig. 3). This depth-dependent increase indicates the emergence of non-trivial spatial structure during training, despite the absence of explicit positional embeddings.

        As expected, the trained intact model exhibits higher SSDC values across all layers, consistent with the direct contribution of explicit positional embeddings. Importantly, however, the presence of a strong SSDC increase in the trained ablated model demonstrates that spatial structure is not solely inherited from positional encodings, but can emerge implicitly through training dynamics and architectural biases.

        Token Cosine Similarity Matrices (Fig. 4) provide a visual confirmation of these trends. The untrained model shows no coherent spatial pattern, with diffuse similarity and no clear evolution across layers. In contrast, the trained ablated model exhibits a progressively sharpening diagonal structure from layer 0 to layer 2, indicating increasing similarity between nearby tokens and the formation of a locality bias. This diagonal becomes more pronounced with depth, aligning with the observed SSDC growth.
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.85\linewidth]{../figures/SSDC_section_42}
            \caption{\textbf{SSDC across depth for an untrained model with random permutation, a trained ablated model, and a trained intact model.} Shaded regions indicate variability across runs.}
            \label{fig:SSDC42}
        \end{figure}
        
        \begin{figure}[H]
            \centering

            \begin{subfigure}{0.36\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_0_untrained_RPI.png}
                \caption{Untrained Ablated Model with Random Permutation Layer 0}
                \label{fig:cosine-ablated-untrained-RPI-0}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.36\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_2_untrained_RPI.png}
                \caption{Untrained Ablated Model with Random Permutation Layer 2}
                \label{fig:cosine-ablated-untrained-RPI-2}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.36\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_0_ablated.png}
                \caption{Trained Ablated Model Layer 0}
                \label{fig:cosine-ablated-0}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.36\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_2_ablated.png}
                \caption{Trained Ablated Model Layer 2}
                \label{fig:cosine-ablated-2}
            \end{subfigure}
            
            \caption{
            \textbf{Representative token cosine similarity matrices.} All matrices share the same color scale.
            }
            \label{fig:token-cosine-similarity-matrices-2}
        \end{figure}
        \begin{figure*}[t]
            \centering
            \begin{subfigure}[b]{0.44\textwidth}
                \includegraphics[width=\textwidth]{../figures/ERM_section_43}
                \caption{Effective Rank across depth (Intact vs Post-hoc Ablated).}
                \label{fig:er_values}
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.44\textwidth}
                \includegraphics[width=\textwidth]{../figures/MCS_section_43}
                \caption{Mean Token Cosine Similarity across depth (Intact vs Post-hoc Ablated).}
                \label{fig:cos_sim_values}
            \end{subfigure}

            \caption{Early-layer representational diversity under intact and post-hoc ablated positional embeddings.
            Left: Effective Rank of the residual stream across layers. Right: Mean token-wise cosine similarity across layers. Results are shown for a fully intact ViT and the same trained model with positional embeddings removed post-hoc at inference time. The intact model exhibits substantially higher Effective Rank at layer 0 followed by an early collapse, while the post-hoc ablated model starts from a low-rank regime and remains consistently lower. Mean token cosine similarity is higher for the post-hoc ablated model across all layers.
            }
            \label{fig:4_3_main}
        \end{figure*}
    \subsection{Positional Embeddings Inject Early-Layer Representational Diversity}

        \textbf{Experimental setup:} We evaluate representational diversity in Vision Transformers using two complementary metrics: the Effective Rank of the residual stream and the mean token-wise cosine similarity. Experiments are conducted on CIFAR-10 using two models: (1) a standard ViT with intact positional embeddings, and (2) the same trained model with positional embeddings removed post-hoc at inference time.

        Effective Rank is computed at layers 0, 2, 4, and 9, following standard practice as a proxy for the dimensional diversity of representations. In parallel, we compute the token-to-token cosine similarity matrix at the same layers and report its mean value as a measure of representational collapse across spatial tokens.

        Crucially, because positional embeddings are removed only at inference time, any observed differences reflect the functional role of positional information during forward computation rather than differences in learned parameters.

        \textbf{Results:} Figure 4 reveals a pronounced difference in representational diversity between intact and post-hoc ablated models that emerges immediately at the input layer. At layer 0, the intact model exhibits an Effective Rank approximately four times higher than that of the post-hoc ablated model, indicating that positional embeddings inject substantial high-dimensional diversity directly into the residual stream prior to any attention-based mixing.

        Strikingly, this initial advantage does not persist unaltered. The intact model undergoes a sharp collapse in Effective Rank within the first two layers, after which its rank stabilizes and remains only slightly higher than that of the post-hoc ablated model for the remainder of the network. In contrast, the post-hoc ablated model begins in a low-rank regime and does not exhibit a comparable early collapse, instead maintaining a relatively stable but consistently lower Effective Rank across depth.

        Mean token cosine similarity provides a complementary perspective. Across all layers and all runs, the post-hoc ablated model exhibits significantly higher token-wise similarity than the intact model, indicating persistent spatial homogenization when positional embeddings are removed. This elevated similarity is present from the earliest layer and does not disappear with depth, suggesting that the lack of positional information induces a sustained form of representational collapse across tokens.

        Taken together, these results suggest a two-stage role for positional embeddings. First, they inject a large amount of representational diversity at the input, dramatically increasing the dimensionality of early representations. Second, the network rapidly compresses this diversity in early layers, likely retaining only task-relevant spatial structure. When positional embeddings are removed post-hoc, this initial high-diversity regime is never formed, and the model operates entirely within a low-rank, spatially homogeneous representational space despite unchanged learned parameters. 
    \clearpage
    
    \subsection{Patch-Relative and Absolute-Position-Based Modes of Spatial Organization}
        \begin{figure}[t]
            \centering
            \includegraphics[width=0.8\linewidth]{../figures/SSDC_section_44}
            \caption{\textbf{SSDC across depth for intact models, and intact/ablated models that have had their tokens permuted randomly at inference.} 
            The SSDC collapses to near-zero values upon permutation of the tokens of the ablated model, whereas the intact model's SSDC only takes a slight hit
            after permutation.
            }
            \label{fig:SSDC_44}
        \end{figure}
        \begin{figure}[t]
            \begin{subfigure}{0.47\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_2_perm_int.png}
                \caption{Token Cosine Similarity Matrix for an intact model (permuted)}
                \label{fig:TCSM_int_44}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.47\linewidth}
                \centering
                \includegraphics[width=\linewidth]{../figures/layer_2_perm_abl.png}
                \caption{Token Cosine Similarity Matrix for an ablated model (permuted)}
                \label{fig:TCSM_abl_44}
            \end{subfigure}
            \caption{\textbf{Representative Token Cosine Similarity Matrices.} Once its tokens are permuted, the ablated model's 
            Token Cosine Similarity Matrix becomes chaotic and loses all spatial structure, whereas the diagonal band persists (though fuzzier)
            in the intact model's.
            }
            \label{fig:TCSM_44}
        \end{figure}
        \textbf{Experimental Setup: } Bla blablalbalbalbalbalbalblablablablablalblablalba

        \textbf{Results: }
\bibliography{references}
\bibliographystyle{icml2026}
\end{document}